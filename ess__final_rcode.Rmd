---
title: "project_ess_final"
author: "Jeremy Knox"
date: "12/8/2018"
output: html_document
---

Libraries and Data Frames:
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(car)
library(userfriendlyscience)
library(knitr)
library(kableExtra)
library(effsize)
library(ggrepel)
library(reshape2)
library(stargazer)
library(Hmisc)
library(lmtest)
library(corrplot)
library(ggplot2)
library(ggmap)
library(maps)
library(mapdata)
library(stringr)
library(dplyr)
library(corrplot)
task1 = read_csv("climate_opinion.csv")
task2 = read.csv("ucsb_climate.csv", row.names = 1)
task3 = read_csv("tmas_df.csv")
task4 = read_csv("PesticideResidues.csv")
task5 = read_csv("ca_county_pesticides.csv")
```



Task 1: Climate Change Opinions (Yale Program on Climate Change Commu- nication)
```{r results=FALSE, results="asis"}
#---- 2 ----#
# correlation matrix 
sapply(task1, class)
subset_task1 = task1 %>% select(happening,consensus,discuss,mediaweekly,bachelors,poverty_rate)

cm = cor(subset_task1)
cm

corrplot(cm, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)

# dependent "happening" is derived from a binomial variable with "yes", "no" or "dont know" responses. Then aggreagated at the state level and given as a percent of respondents who repsponded yes (is an estimate?).
lm = lm(data = task1, happening ~ bachelors + poverty_rate + coastline) 
summary(lm) # NOT INCLUDED variables because of likely reverse causuality: "consensus", "discuss", "mediaweekly"
plot(lm) # looks homoskedastic 
bptest(lm) # p = .65 thus residuals most likley constant => homoskedastic 

#---- 3 ----#
lm_table <- stargazer(lm, type = "html", title = "Global Warming is Happening (Yes/No) Linear Model", digits = 2, align = TRUE, dep.var.labels = "Global Warming is Happening", covariate.labels = c("Bachelors", "Poverty Rate", "Coastline","Constant"), out="model.htm")
lm_table

##### exploring interactions => NO interactions needed ####
task1_s1 = task1 %>% 
  filter(bachelors < 40)
interaction1 = ggplot(data = task1_s1, aes(x=bachelors, y=happening, color=coastline), alpha=.1) +
  geom_point(shape=1) +
  stat_smooth(aes(group = coastline), method = "lm", formula = y ~ x, se = FALSE)
interaction1
interaction2 = ggplot(data = task1_s1, aes(x=poverty_rate, y=happening, color=coastline), alpha=.1) +
  geom_point(shape=1) +
  stat_smooth(aes(group = coastline), method = "lm", formula = y ~ x, se = FALSE)
interaction2
interaction3 = ggplot(data = task1_s1, aes(x=GeoName, y=happening, color=coastline), alpha=.1) +
  geom_point(shape=1) +
  stat_smooth(aes(group = coastline), method = "lm", formula = y ~ x, se = FALSE)
interaction3 
# NOT INCLUDING states as interacting it with coastline would incease amount of DV by 100%. 
```
#Task 1 Answers:
(a) A multivariable linear regression was employed to explore relationships between education attainment, poverty levels and coastline on the estimated proportion of people who believe that global warming is happening. Multivariable linear regression was used beacuse there are multiple dependent variables with a single continuous independent variable. 

(b) An exploratory correlation matrix for all continuous variables (make it readable, but it does not need to be finalized and you do not need to add a figure caption).
*code*

(c) Table 1. Multiple linear regression of estimated percentate of people who think global warming is happening on education attainment, poverty levels and coastline. Coefficient for *coastline* is in reference to states with no coastline. Also included in the table are indicators of model fit. Data was aggreagated at the state level, resulting in proportions of people per state. Sources: (1) Climate opinion data: Yale Climate Opinion Maps (2018): By Jennifer Marlon, Peter Howe, Matto Mildenberger, Anthony Leiserowitz and Xinran Wang. (2) *Education attainment and poverty levels: Bureau, U.S. Census. “2011-2015 American Community Survey 5-Year Estimates”. factfinder.census.gov. Retrieved 2017-07-02.

(d) On average, the proportions of people per state who live in coastal states are 3.35 percent more likely to have answered yes to the question, "Global warming is happening?", as compared to people who live in states with no coastline - holding all other variables in the model constant. 
On average, a 1 percent increase in proportion of bachelors per state will result in a 0.63 percent increase in proportion of people per state who responded yesr to the question, "Global warming is happening?" - holding all other variables in the model constant. 

(e) According to diagnostics plots and Breusch-Pagan test, the above model looks to be homoskedastic. Also, the residuals look to be normally distributed. 
#


Task 2: UCSB Campus Climate Survey - Perceptions of Campus Respectfulness by Respondent Race/Ethnicity
```{r results=FALSE}
# compare proportions
task2_simple = task2%>% 
  select(Very.Respectful,
         Respectful,
         Disrespectful,
         Very.Disrespectful)
chisq <- chisq.test(task2_simple)

chisq # p < 0.001 => reject null => There is a siginificant association between ethnicity and perception of campus respectfulness (x^2(18) = 1489.6, p < 0.001). 

# Kruskal-Wallace?
# # exploring visually
# chisq$observed
# round(chisq$expected,2)
# round(chisq$residuals, 3)
# corrplot(chisq$residuals, is.cor = FALSE)
# 
# contrib <- 100*chisq$residuals^2/chisq$statistic
# round(contrib, 3)
# corrplot(contrib, is.cor = FALSE)
```
#Task 2 Answers: 
(a) A chi squared test will be used to test the question: Is there a significant association between ethinicity and perception of campus respectfullness?

(b) There is a siginificant association between ethnicity and perception of campus respectfulness (x^2(18) = 1489.6, p < 0.001).

(c) *copied data frame to word (source local file)* NEED FIGURE CAPTION

(d) Twenty-four percent (highest) of respondents who indicated overall campus climate was "very respectufl" were from White racial/ethnic backgrounds (Table XXX). As compared to twelve percent (lowest) of people from Middle Eastern/South Asian/North African racial/ethnic backgrounds. Of respondents who answered campus climate was "very disrespectful", seven percent were white (lowest) while twenty-two percent (highest) were from black racial/ethnic backgrounds.

#


Task 3: Effect of sex and age on self-consciousness (Taylor Manifest Anxiety Scale)
```{r results=FALSE, results="asis"}
sapply(task3, class)

task3$response = as.logical(task3$response)

glm = glm(response ~ age + sex_mf, family = binomial, data = task3)
summary(glm)
plot(glm) # cannot tell, doing Breusch-Pagan test

glm_table = stargazer(lm, type = "html", title = "I am Usually Self-Conscious Logistic Model", digits = 2, align = TRUE, dep.var.labels = "I am Usually Self-Conscious (Yes)", covariate.labels = c("Age", "Sex", "Family","Constant"), out="model.htm")
glm_table

age = rep(seq(from = 0, to = 100), 2)
f = rep("Female", 101)
m = rep("Male", 101)
mf = c(f,m)
age_mf = data.frame(age, mf)
colnames(age_mf) = c("age", "sex_mf")

probs = predict(glm, newdata=age_mf, type = "response", se.fit=T)

g_data = data.frame(age_mf, probs$fit, probs$se.fit)
g_data

colnames(g_data) = c("Age", "Sex", "Probability", "SE")

graph = ggplot(g_data, aes(x = Age, y = Probability))+
  geom_line(aes(color = Sex)) +
  geom_ribbon(aes(ymin = Probability - SE, ymax = Probability + SE, fill = Sex), alpha = .3 )+
  theme_classic()+
  scale_y_continuous(limits = c(0,1)) +
  labs(title = "BLAH")
graph



##### exploring interactions => NO interactions needed ####
interaction = ggplot(data = task3, aes(x=age, y=response, color=sex_mf), alpha=.01) +
  geom_point(shape=1) +
  stat_smooth(aes(group = sex_mf), method = "lm", formula = y ~ x, se = FALSE)
interaction
```
#Task 3 Answers:


#


Task 4: Pyraclostrobin residues on crops
```{r results=FALSE}
task41 = task4 %>%
  select(COMMODITY, `CHEMICAL DETECTED (IF ANY)`, `AMOUNT OF CHEMICAL DETECTED (PPM)`) %>%
  rename(commodity = COMMODITY) %>%
  rename(chemical = `CHEMICAL DETECTED (IF ANY)`) %>%
  rename(ppm = `AMOUNT OF CHEMICAL DETECTED (PPM)`)
task42 = task41 %>% 
  mutate(detected = case_when(ppm > 0 ~ 1,
                              ppm == 0 ~ 0))
task4_simpl = task42 %>% 
  filter(commodity == "STRAWBERRY (ALL OR UNSPEC)" | commodity == "CARROTS (ROOT CROP)") %>% 
  mutate(commodity = case_when(commodity == "STRAWBERRY (ALL OR UNSPEC)" ~ "strawberry",
                   commodity == "CARROTS (ROOT CROP)" ~ "carrot")) %>% 
  filter(chemical == "PYRACLOSTROBIN")

h = ggplot(task4_simpl, aes(ppm)) +
  geom_histogram() +
  facet_wrap("commodity")
h 
qqs = ggplot(task4_simpl, aes(sample = ppm)) +
  geom_qq() + 
  facet_wrap("commodity", scales = "free") 
qqs

strawberry = task4_simpl %>% 
  filter(commodity == "strawberry") %>% 
  pull(ppm)
carrot = task4_simpl %>% 
  filter(commodity == "carrot") %>% 
  pull(ppm)


#Mann-Whitney U
mwu_emp = wilcox.test(strawberry,carrot)
mwu_emp # p = 0  significant, ranks are NOT equal)

effsize_emp = cliff.delta(strawberry,carrot) # d estimate = 0.26 (small)
effsize_emp
```
#Task 4 Answers: 
(a) Based on histograms and quantile-quantile plots (see graphs) of strwaberries and carrots that had pyraclostrobin detected showed a non-normal distribution. Additionally, the number of observatiosn for carrots (n = 15) restricts us from using the central limit theorem to run parametric tests. 

(b) Ranking (pyraclostrobin in ppm) differed between the groups, with a higher median of 0.07 for stawberry (n = 40), versus a sample median of 0.02 for carrot (n = 15). A Mann-Whitney U test revealed there is a significant difference in the amount of pyraclostrobin detected between strawberries and carrots (W = 508.5, p < 0.001). Additionally, the effect size is large (Cliff's Delta = 0.7). 
#


Task 5: Pesticides by County, California (2014)
```{r results=FALSE}
task5_simpl = task5 %>% 
  rename(subregion = County) %>% 
  rename(pound = `Pounds Active Pesticide Ingredient Used`) %>% 
  rename(rank = `State Ranking`) %>% 
  rename(area = `County Area (Square Miles)`) %>%
  mutate(pound_per_sqmile = pound/area) %>% 
  mutate(subregion = tolower(subregion))

task5_short = task5_simpl %>% 
  filter(subregion == "san joaquin"| subregion ==  "fresno"| subregion == "sutter"| subregion == "kings"| subregion == "stanislaus"| subregion == "merced"| subregion == "madera"| subregion == "santa cruz"| subregion == "sacramento"| subregion == "ventura")

short_pop_and_area = task5_short %>% 
  select(subregion,pound,area)
  
  
pop_and_area = task5_simpl %>% 
  select(subregion, pound, area)


states <- map_data("state")
ca_df <- subset(states, region == "california")
counties <- map_data("county")
ca_county <- subset(counties, region == "california")

ca_top_county <- subset(counties, region == "california") %>% 
  filter(subregion == "san joaquin"| subregion ==  "fresno"| subregion == "sutter"| subregion == "kings"| subregion == "stanislaus"| subregion == "merced"| subregion == "madera"| subregion == "santa cruz"| subregion == "sacramento"| subregion == "ventura")


#### ALL of California ####
ca_base <- ggplot(data = ca_df, mapping = aes(x = long, y = lat, group = group)) +
  coord_fixed(1.3) + 
  geom_polygon(color = "black", fill = "gray") + 
  theme_nothing() + 
  geom_polygon(data = ca_county, fill = NA, color = "white") +
  geom_polygon(color = "black", fill = NA)  # get the state border back on top

cacopa <- inner_join(ca_county, pop_and_area, by = "subregion")
cacopa$pound_per_mile <- cacopa$pound / cacopa$area

ditch_the_axes <- theme(
  axis.text = element_blank(),
  axis.line = element_blank(),
  axis.ticks = element_blank(),
  panel.border = element_blank(),
  panel.grid = element_blank(),
  axis.title = element_blank()
  )

gross <- ca_base + 
      geom_polygon(data = cacopa, aes(fill = pound_per_mile), color = "white") +
      geom_polygon(color = "black", fill = NA) +
      theme(plot.title = element_text(hjust = 0.5)) +
      theme_bw() +
      ditch_the_axes +
      scale_fill_gradientn(colours = rev(rainbow(2)), 
                           breaks = c(1, 10, 100, 1000, 3300, 8600),
                           trans = "log10") +
      labs(fill = "Pounds of Pesticide per Square Mile", title = "California - Pounds of Pesticide per County")
gross


#### TOP counties in California ####
ca_top <- ggplot(data = ca_df, mapping = aes(x = long, y = lat, group = group)) +
  coord_fixed(1.3) + 
  geom_polygon(color = "black", fill = "gray") + 
  theme_nothing() + 
  geom_polygon(data = ca_top_county, fill = NA, color = "white") +
  # geom_point(data = labs, aes(x = long, y = lat), color = "black", size = 5) +
  # geom_point(data = labs, aes(x = long, y = lat), color = "yellow", size = 4) +
  # geom_text(data = labs, aes(label = paste("  ", as.character(names), sep="")), angle = 60, hjust = 0, color = "yellow") +
  geom_polygon(color = "black", fill = NA)  # get the state border back on top

cacopa <- inner_join(ca_top_county, short_pop_and_area, by = "subregion")
cacopa$pound_per_mile <- cacopa$pound / cacopa$area

##### 
labs <- data.frame(
  long = c(-120.1890, -119.2321, -121.7527, -118.5551, -120.9876, -120.4830, -120.0607, -122.0308, -121.4944, -119.2945),
  lat = c(36.6066, 36.9859, 39.1599, 36.8879, 37.5091, 37.3022, 36.9613, 36.9741, 38.5816, 34.2805),
  names = c("San Joaquin", "Fresno", "Sutter", "Kings", "Stanislaus", "Merced", "Madera", "Santa Cruz", "Sacramento", "Ventura"),
  stringsAsFactors = FALSE
  )  

label = distinct(cacopa, subregion, .keep_all = TRUE)

test = cacopa %>%
  select(long,lat,subregion) %>%
  filter(subregion == "sacramento") %>%
  filter(long == max(long)) %>%
  filter(lat == max(lat))

# "san joaquin" 36.6066° N, 120.1890° W
# "fresno" 36.9859° N, 119.2321° W
# "sutter" 39.1599° N, 121.7527° W
# "kings" 36.8879° N, 118.5551° W
# "stanislaus" 37.5091° N, 120.9876° W
# "merced" 37.3022° N, 120.4830° W
# "madera" 36.9613° N, 120.0607° W
# "santa cruz" 36.9741° N, 122.0308° W
# "sacramento" 38.5816° N, 121.4944° W
# "ventura" 34.2805° N, 119.2945° W
##### 

gross_top <- ca_top + 
      geom_polygon(data = cacopa, aes(fill = pound_per_mile), color = "white") +
      geom_polygon(color = "black", fill = NA) +
      theme(plot.title = element_text(hjust = 0.5)) +
      theme_bw() +
      ditch_the_axes +
      scale_fill_gradientn(colours = rev(rainbow(2)), 
                           breaks = c(4000, 5000, 6000, 7000, 8000))+
                           #trans = "log2") +
      coord_fixed(xlim = c(-123, -118.0), ylim = c(34, 39.1), ratio = 1.3) +
      labs(fill = "Pounds of Pesticide per Square Mile") +
     # geom_text(data = cacopa, aes(label = subregion, x = long, y = lat), size = 2)
      geom_text(data=cacopa1, aes(label = subregion), size=3) +
      labs(title ="California Top 10 Counties for Pounds of Pesticide per County") 
        
gross_top


```
#Task 5 Answers: 
See graph.
#



